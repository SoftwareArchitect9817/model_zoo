docker run --gpus all -it --rm \
-v `pwd`:/home/user/workdir \
ghcr.io/pinto0309/openvino2tensorflow:latest

MODEL=perceptual_reflection_removal
H=180
W=320
saved_model_to_tflite \
--saved_model_dir_path saved_model_${H}x${W} \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_type 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_onnx \
--onnx_opset 11
mv tflite_from_saved_model/* saved_model_${H}x${W}
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP32 \
--data_type FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP16 \
--data_type FP16

H=240
W=320
saved_model_to_tflite \
--saved_model_dir_path saved_model_${H}x${W} \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_type 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_onnx \
--onnx_opset 11
mv tflite_from_saved_model/* saved_model_${H}x${W}
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP32 \
--data_type FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP16 \
--data_type FP16

H=360
W=480
saved_model_to_tflite \
--saved_model_dir_path saved_model_${H}x${W} \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_type 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_onnx \
--onnx_opset 11
mv tflite_from_saved_model/* saved_model_${H}x${W}
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP32 \
--data_type FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP16 \
--data_type FP16

H=360
W=640
saved_model_to_tflite \
--saved_model_dir_path saved_model_${H}x${W} \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_type 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_onnx \
--onnx_opset 11
mv tflite_from_saved_model/* saved_model_${H}x${W}
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP32 \
--data_type FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP16 \
--data_type FP16

H=480
W=640
saved_model_to_tflite \
--saved_model_dir_path saved_model_${H}x${W} \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_type 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_onnx \
--onnx_opset 11
mv tflite_from_saved_model/* saved_model_${H}x${W}
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP32 \
--data_type FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP16 \
--data_type FP16

H=720
W=1280
saved_model_to_tflite \
--saved_model_dir_path saved_model_${H}x${W} \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_onnx \
--onnx_opset 11
mv tflite_from_saved_model/* saved_model_${H}x${W}
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP32 \
--data_type FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \
--saved_model_dir saved_model_${H}x${W} \
--output_dir saved_model_${H}x${W}/openvino/FP16 \
--data_type FP16
